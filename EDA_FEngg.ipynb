{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import sklearn\n",
    "from ast import literal_eval\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv file\n",
    "df = pd.read_csv('drugs_clean_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### avg rating of all drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = df[['drugName','rating']]\n",
    "\n",
    "avg_rating = rating.groupby('drugName').mean().round(2)\n",
    "avg_rating.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'median: {avg_rating.median()}')\n",
    "print (f'common rating: {avg_rating.mode()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- average rating: 7.40\n",
    "- mid rating: 7.75\n",
    "- common rating: 10.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drugs with unsatisfied ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsatisfied = avg_rating[avg_rating['rating'] < 5]\n",
    "unsatisfied.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drugs with satisfied ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfied = avg_rating[avg_rating['rating'] > 5]\n",
    "satisfied.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'satisfied: {satisfied.count()}')\n",
    "print(f'unsatisfied: {unsatisfied.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very imbalanced. Unsatisfied ratings make up only 11% of the data, while satisfied ratings make up 89%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between words and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_rating = df[['stemmed','rating']]\n",
    "keywords_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avg length of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = df['review'].str.split()\n",
    "df['review_wordcount'] = review.apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_length = df['review_wordcount'].mean().round(2)\n",
    "avg_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average length of reviews is 84.7 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats of usefulCount score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_useful = df['usefulCount'].describe().round(2)\n",
    "avg_useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average number of users who found a review useful is 28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find words commonly associated with certain rating values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by rating\n",
    "groups = df[['rating','stemmed']]\n",
    "groups.sort_values('rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all stemmed words into one row for each rating value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check each item in column is a list and not a string\n",
    "groups['stemmed'] = groups['stemmed'].apply(lambda x: literal_eval(x) if isinstance(x, str) else x) # .loc used to avoid copying\n",
    "\n",
    "drugs_keywords = groups.groupby('rating')['stemmed'].agg(sum)\n",
    "drugs_keywords = drugs_keywords.reset_index()\n",
    "drugs_keywords.columns = ['rating', 'words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_keywords.to_csv('keywords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.read_csv('keywords.csv')\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract top 200 words from words from words list and store in new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_250(words):\n",
    "    if isinstance(words,str): \n",
    "        words = literal_eval(words) # make sure the object is treated as a list\n",
    "    counts = Counter(words)\n",
    "    return [word for word, _ in counts.most_common(250)] # returns top 250 objects\n",
    "\n",
    "# use joblib to optimize task by parallel processing\n",
    "top_250_words = Parallel(n_jobs=-1)(delayed(top_250)(words) for words in ddf['words'])\n",
    "\n",
    "ddf['top_250_words'] = top_250_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.drop(columns=['top_200_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_explode = ddf.explode('top_250_words')\n",
    "frequency_table = pd.crosstab(index=ddf_explode['top_250_words'], columns=ddf_explode['rating'])\n",
    "\n",
    "columns = {rating: [] for rating in range(1,11)}\n",
    "top_250_df = pd.DataFrame(columns)\n",
    "\n",
    "for rating in range(1,11):\n",
    "    if rating in frequency_table.columns:\n",
    "        top_250 = frequency_table.nlargest(250,rating).index.tolist()\n",
    "        top_250_df[rating] = pd.Series(top_250)\n",
    "\n",
    "top_250_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_250_df.to_csv('top_250.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create artificial data to balance out data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('drugs_clean_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['class'].value_counts()\n",
    "max_size = class_counts.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = pd.DataFrame()\n",
    "\n",
    "for class_index, group in df.groupby('class'):\n",
    "    oversampled_group = group.sample(n=max_size, replace=True, random_state=42)\n",
    "    balanced_df = pd.concat([balanced_df, oversampled_group], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all data is equally represented/balanced now in the class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.to_csv('balanced_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
