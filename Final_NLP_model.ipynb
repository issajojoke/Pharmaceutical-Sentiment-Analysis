{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import ast\n",
    "import joblib\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_rating(rating):\n",
    "    if rating <= 4:\n",
    "        return 1\n",
    "    elif 4 < rating <= 7:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def text_preprocessing_pipeline(df, text_column):\n",
    "    # replace char\n",
    "    replacements = {\n",
    "        '&#039;': \"'\",\n",
    "        '&rsquo;': \"'\",\n",
    "        '&amp;': \"&\",\n",
    "        '&quot;': '\"'\n",
    "    }\n",
    "    for key, value in replacements.items():\n",
    "        df[text_column] = df[text_column].str.replace(key, value, regex=False)\n",
    "        \n",
    "    # tokenize\n",
    "    df['tokens'] = df[text_column].apply(word_tokenize)\n",
    "\n",
    "    # convert to lowercase and remove non-alphabetic characters\n",
    "    df['tokens'] = df['tokens'].apply(lambda tokens: [token.lower() for token in tokens if token.isalpha()])\n",
    "\n",
    "    # remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    df['tokens'] = df['tokens'].apply(lambda words: [word.translate(table) for word in words])\n",
    "\n",
    "    # remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['tokens'] = df['tokens'].apply(lambda words: [word for word in words if word not in stop_words])\n",
    "\n",
    "    # stem\n",
    "    porter = PorterStemmer()\n",
    "    df['stemmed'] = df['tokens'].apply(lambda words: [porter.stem(word) for word in words])\n",
    "\n",
    "    # apply group_rating() to rating column\n",
    "    df['class'] = df['rating'].apply(group_rating)\n",
    "\n",
    "    # convert stemmed words back to string for vectorization\n",
    "    df['stemmed'] = df['stemmed'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load the trained model and vectorizer\n",
    "svm_model = joblib.load('svm_model.pkl')\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.pkl')\n",
    "\n",
    "def classify_text(df):\n",
    "    # preprocess text\n",
    "    df = text_preprocessing_pipeline(df, 'review')\n",
    "    \n",
    "    # vectorization\n",
    "    X = tfidf_vectorizer.transform(df['stemmed'])\n",
    "    \n",
    "    # classify via SVM\n",
    "    df['class'] = svm_model.predict(X)\n",
    "    df['class'] = df['class'] + 1  # Adjust class labels to be 1-3 instead of 0-2\n",
    "\n",
    "    return df\n",
    "\n",
    "# load data into df\n",
    "file_path = 'csv file'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# classify data\n",
    "classified_df = classify_text(df)\n",
    "classified_df.drop([col for col in classified_df.columns if 'Unnamed' in col], axis=1, inplace=True) # drop unnamed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display classified df\n",
    "classified_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
